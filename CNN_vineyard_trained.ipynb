{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EnayatAria/UAV-image-classification-by-CNN/blob/main/CNN_vineyard_trained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k1_P5LyGKkv",
        "outputId": "21ef16f3-6f55-437a-d5e1-1c140ecd301b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception reporting mode: Verbose\n",
            "Automatic pdb calling has been turned ON\n"
          ]
        }
      ],
      "source": [
        "# This part is for debugging the code\n",
        "%xmode Verbose\n",
        "%pdb on\n",
        "from IPython.core.debugger import set_trace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw1VZxXa8GDV",
        "outputId": "f8d4a472-ebb4-4624-bc09-d1536f66464f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spectral\n",
            "  Downloading spectral-0.22.4-py3-none-any.whl (212 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▌                              | 10 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 20 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 212 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from spectral) (1.19.5)\n",
            "Installing collected packages: spectral\n",
            "Successfully installed spectral-0.22.4\n"
          ]
        }
      ],
      "source": [
        "!pip install spectral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncFYF2emUYXP"
      },
      "outputs": [],
      "source": [
        "from scipy import io\n",
        "import numpy as np\n",
        "import spectral.io.envi as envi\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as dataf\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiC5oEYa4fag"
      },
      "outputs": [],
      "source": [
        "# reading the image data and ground truth\n",
        "dataset='Sinkhorn40000_TS'\n",
        "scene='subset1'\n",
        "# for lambda_reg in range(40000, 40001):\n",
        "OV_type=['EMD', 'Sinkhorn','L1L2','Laplace']\n",
        "# OV_type=['Laplace']\n",
        "\n",
        "dir_list=[ 'without Grass transformation using classification map', 'with Grass transformation using training site',  \n",
        "          'with Grass transformation using classification map','without Grass transformation using training site']\n",
        "\n",
        "# for iii in range (40000, 1000000, 50000):\n",
        "\n",
        "for dir in dir_list:\n",
        "  '''\n",
        "  if dir == 'without Grass transformation using training site':\n",
        "    ov_t = 'ts'\n",
        "    # lambda_reg=340000\n",
        "  else:\n",
        "    ov_t = 'cm'\n",
        "    # lambda_reg=940000\n",
        "    '''\n",
        "  reg = 1000\n",
        "  while reg<=1000000:\n",
        "  # for ov_t in OV_type:\n",
        "    for iii in range (40000, 1000000, 200000):\n",
        "      dataset='L1L2_lambda_'+str(iii)+'_regGS_'+str(reg) \n",
        "      #DataPath = '/content/drive/MyDrive/Gaillac-UAV-ML-2016/subset'\n",
        "      #txtPath='/content/drive/MyDrive/Gaillac-UAV-ML-2016/roi_txt.txt'\n",
        "      #DataPath = '/content/drive/MyDrive/dataset/Minervois/transformed_sh'\n",
        "      DataPath_target ='/content/drive/MyDrive/dataset/Minervois/'+scene+'/'+ dir + '/REG_GS/'+dataset\n",
        "      #txtPath='/content/drive/MyDrive/dataset/Minervois/ENVI/classes.txt'\n",
        "      # savepath ='/content/drive/MyDrive/Gaillac-UAV-ML-2016/2DCNN-14.mat'\n",
        "\n",
        "      # Reading envi dataset\n",
        "      img =envi.open(DataPath_target+'.hdr', DataPath_target+'.img')\n",
        "      Data=img.load()\n",
        "      #Data=Data[1050:1550,800:1300,:]\n",
        "      #Data = Data.astype(np.float32)\n",
        "\n",
        "      # some initialization\n",
        "      patchsize = 16  # input spatial size for 2D-CNN\n",
        "      batchsize = 128  # select from [16, 32, 64, 128], the best is 64\n",
        "      EPOCH = 200\n",
        "      LR = 0.001\n",
        "\n",
        "      # without dimensionality reduction\n",
        "      pad_width = np.floor(patchsize / 2)\n",
        "      pad_width = np.int(pad_width)\n",
        "\n",
        "      # standardization method 2: map to zero mean and one std\n",
        "      [m, n, l] = np.shape(Data)\n",
        "      for i in range(l):\n",
        "          mean = np.mean(Data[:, :, i])\n",
        "          std = np.std(Data[:, :, i])\n",
        "          Data[:, :, i] = (Data[:, :, i] - mean) / std\n",
        "\n",
        "      Classes=4\n",
        "\n",
        "      x = Data\n",
        "      # boundary interpolation\n",
        "      temp = x[:, :, 0]\n",
        "      temp=np.squeeze(temp)\n",
        "      temp2 = np.pad(temp, pad_width, 'symmetric')\n",
        "      [m2, n2] = temp2.shape\n",
        "      x2 = np.empty((m2, n2, l), dtype='float32')\n",
        "      for i in range(l):\n",
        "          temp = np.squeeze(x[:, :, i])\n",
        "          pad_width = np.floor(patchsize / 2)\n",
        "          pad_width = np.int(pad_width)\n",
        "          temp2 = np.pad(temp, pad_width, 'symmetric')\n",
        "          x2[:, :, i] = temp2\n",
        "\n",
        "      # to check if cuda is available or not\n",
        "      # when the GPU is on from the 'Runtime' tab, the result would be 'True'\n",
        "      torch.cuda.is_available()\n",
        "\n",
        "      # construct the network\n",
        "      class CNN(nn.Module): # nn.Module is the base class for all neural network modules\n",
        "          def __init__(self):\n",
        "              super(CNN, self).__init__()  # super() allows us to access methods in the base class\n",
        "              self.conv1 = nn.Sequential(  # a sequential container\n",
        "                  nn.Conv2d(\n",
        "                      in_channels=l,\n",
        "                      out_channels=OutChannel,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1,\n",
        "                  ),\n",
        "                  nn.BatchNorm2d(OutChannel),\n",
        "                  nn.ReLU(),\n",
        "                  nn.MaxPool2d(kernel_size=2),\n",
        "              )\n",
        "              self.conv2 = nn.Sequential(\n",
        "                  nn.Conv2d(OutChannel, OutChannel * 2, 3, 1, 1),\n",
        "                  nn.BatchNorm2d(OutChannel * 2),\n",
        "                  nn.ReLU(),\n",
        "                  nn.MaxPool2d(2),\n",
        "                  # nn.Dropout(0.5),\n",
        "\n",
        "              )\n",
        "              self.conv3 = nn.Sequential(\n",
        "                  nn.Conv2d(OutChannel * 2, OutChannel * 4, 3, 1, 1),\n",
        "                  nn.BatchNorm2d(OutChannel * 4),\n",
        "                  nn.ReLU(),\n",
        "                  nn.AdaptiveMaxPool2d(1),\n",
        "                  # nn.Dropout(0.5),\n",
        "\n",
        "              )\n",
        "\n",
        "              self.out = nn.Linear(OutChannel * 4, Classes)  # fully connected layer, output 16 classes\n",
        "          \n",
        "          def forward(self, x):\n",
        "              #set_trace()\n",
        "              x = self.conv1(x)\n",
        "              x = self.conv2(x)\n",
        "              x = self.conv3(x)\n",
        "              x = x.view(x.size(0), -1)  # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
        "              output = self.out(x)\n",
        "              return output\n",
        "\n",
        "      OutChannel = 32\n",
        "      cnn = CNN()\n",
        "      print('The structure of the designed network', cnn)\n",
        "\n",
        "      # move model to GPU\n",
        "      cnn.cuda()\n",
        "      optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)  # optimize all cnn parameters\n",
        "      loss_func = nn.CrossEntropyLoss()  # the target label is not one-hotted\n",
        "      BestAcc = 0\n",
        "\n",
        "      # show the whole image\n",
        "      # The whole data is too big to test in one time; So dividing it into several parts\n",
        "\n",
        "      cnn.load_state_dict(torch.load('/content/drive/MyDrive/Gaillac-UAV-ML-2016/net_params_2DCNN2.pkl'))#, map_location=torch.device('cpu')))\n",
        "\n",
        "      part = 5000\n",
        "      pred_all = np.empty((m*n, 1), dtype='float32')\n",
        "\n",
        "      number = m*n//part\n",
        "      for i in range(number):\n",
        "          D = np.empty((part, l, patchsize, patchsize), dtype='float32')\n",
        "          count = 0\n",
        "          for j in range(i*part, (i+1)*part):\n",
        "              row = j//n\n",
        "              col = j - row*n\n",
        "              row2 = row + pad_width\n",
        "              col2 = col + pad_width\n",
        "              patch = x2[(row2 - pad_width):(row2 + pad_width), (col2 - pad_width):(col2 + pad_width), :]\n",
        "              patch = np.reshape(patch, (patchsize * patchsize, l))\n",
        "              patch = np.transpose(patch)\n",
        "              patch = np.reshape(patch, (l, patchsize, patchsize))\n",
        "              D[count, :, :, :] = patch\n",
        "              count += 1\n",
        "\n",
        "          temp = torch.from_numpy(D)\n",
        "          temp = temp.cuda()\n",
        "          temp2 = cnn(temp)\n",
        "          temp3 = torch.max(temp2, 1)[1].squeeze()\n",
        "          pred_all[i*part:(i+1)*part, 0] = temp3.cpu()\n",
        "          del temp, temp2, temp3, D\n",
        "\n",
        "      if (i+1)*part < m*n:\n",
        "          D = np.empty((m*n-(i+1)*part, l, patchsize, patchsize), dtype='float32')\n",
        "          count = 0\n",
        "          for j in range((i+1)*part, m*n):\n",
        "              row = j // n\n",
        "              col = j - row * n\n",
        "              row2 = row + pad_width\n",
        "              col2 = col + pad_width\n",
        "              patch = x2[(row2 - pad_width):(row2 + pad_width), (col2 - pad_width):(col2 + pad_width), :]\n",
        "              patch = np.reshape(patch, (patchsize * patchsize, l))\n",
        "              patch = np.transpose(patch)\n",
        "              patch = np.reshape(patch, (l, patchsize, patchsize))\n",
        "              D[count, :, :, :] = patch\n",
        "              count += 1\n",
        "\n",
        "          temp = torch.from_numpy(D)\n",
        "          temp = temp.cuda()\n",
        "          temp2 = cnn(temp)\n",
        "          temp3 = torch.max(temp2, 1)[1].squeeze()\n",
        "          pred_all[(i + 1) * part:m*n, 0] = temp3.cpu()\n",
        "          del temp, temp2, temp3, D\n",
        "\n",
        "\n",
        "      pred_all = np.reshape(pred_all, (m, n)) + 1\n",
        "      '''\n",
        "      OA = OA.numpy()\n",
        "      pred_y = pred_y.cpu()\n",
        "      pred_y = pred_y.numpy()\n",
        "      TestDataLabel = TestLabel.cpu()\n",
        "      TestDataLabel = TestDataLabel.numpy()\n",
        "\n",
        "      io.savemat(savepath, {'PredAll': pred_all, 'OA': OA, 'TestPre': pred_y, 'TestLabel': TestDataLabel})\n",
        "      '''\n",
        "      # print io.loadmat(savepath)\n",
        "      #\n",
        "\n",
        "      plt.figure()\n",
        "      plt.imshow(pred_all)\n",
        "      plt.show()\n",
        "\n",
        "      import matplotlib.pyplot as plt\n",
        "      from matplotlib import cm\n",
        "      from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
        "\n",
        "      #  matplotlib color specification: https://matplotlib.org/stable/tutorials/colors/colors.html\n",
        "      cmap = ListedColormap([\"red\", \"lightgreen\", \"darkgreen\", \"yellow\"])\n",
        "      #plot_examples([cmap])\n",
        "\n",
        "\n",
        "      plt.figure()\n",
        "      plt.imshow(pred_all, cmap=cmap)\n",
        "      plt.show()\n",
        "\n",
        "      import matplotlib.pyplot as plt\n",
        "      from datetime import datetime\n",
        "      now = datetime.now()\n",
        "      dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "      md=img.metadata\n",
        "      #set_trace()\n",
        "      md['description'] = ' classification '+dataset+' transformed using training site '+dt_string\n",
        "      del md['band names']\n",
        "      class_names=['Unclassified', 'Soil', 'Vine', 'Shadow', 'Grass']\n",
        "      class_colors=[(0,   0,   0), (254,   0,   0), (144, 238, 144), (0, 100,   1), (255, 255,   1)]\n",
        "      #img = envi.create_image('savemappath', md)\n",
        "      #set_trace()\n",
        "      envi.save_classification(DataPath_target+'_classification.hdr' , \n",
        "                              pred_all, dtype=np.float32, metadata=md, force=True, class_names=class_names, class_colors=class_colors)\n",
        "    reg*=10\n",
        "      #savemappath='/content/drive/MyDrive/Gaillac-UAV-ML-2016/ClassifiedMap.hdr'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hj5FExi0h92z",
        "outputId": "e8d148fd-190a-4ba0-8495-ab1c911d5870"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/dataset/Minervois/subset1/best_classification_res(reg_e_chnage)/Sinkhorn40000_TS'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DataPath_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdNTiO8Tsua0",
        "outputId": "482eefc5-8464-4ef3-d172-b4a71af34468"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-3.9309263e-08  3.2398106e-07 -8.4236262e-08  2.0390749e-07\n",
            " -2.1898747e-07]\n"
          ]
        }
      ],
      "source": [
        "print(np.mean(np.mean(Data, axis=0), axis=0))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN_vineyard_trained.ipynb",
      "provenance": [],
      "mount_file_id": "1QHY7LkK4hy6pSfadoP_EY-mIV-MZdCLT",
      "authorship_tag": "ABX9TyNb5GDJmMqf8KCjQSf7cfj4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}